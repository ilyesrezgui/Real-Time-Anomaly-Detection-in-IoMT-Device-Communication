# -*- coding: utf-8 -*-
"""Data_Understanding_and_Visualization_IoMT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yHn865eGiD5nPvMIyX08flb8_16942E6
"""

# Commented out IPython magic to ensure Python compatibility.
# ==========================================
# 1Ô∏è‚É£ Setup and Imports
# ==========================================
from google.colab import drive
drive.mount('/content/drive')

# %cd /content/drive/MyDrive/IoMT-AD-Project/notebooks

!pip install pandas numpy matplotlib seaborn kagglehub

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import kagglehub

sns.set(style="whitegrid", palette="muted", font_scale=1.1)

# ==========================================
# 2Ô∏è‚É£ Load Dataset
# ==========================================
path = kagglehub.dataset_download("himadri07/ciciot2023")
print("‚úÖ Dataset downloaded to:", path)

base_path = os.path.join(path, "CICIOT23")

train_path = os.path.join(base_path, "train", "train.csv")
test_path = os.path.join(base_path, "test", "test.csv")
val_path = os.path.join(base_path, "validation", "validation.csv")

train_df = pd.read_csv(train_path)
test_df = pd.read_csv(test_path)
val_df = pd.read_csv(val_path)

print(f"Train: {train_df.shape}, Test: {test_df.shape}, Validation: {val_df.shape}")
train_df.head(10)

# ==========================================
# 3Ô∏è‚É£ General Dataset Information
# ==========================================
print("üß≠ Basic Info:")
train_df.info()

print("\nüìä Missing Values:")
print(train_df.isnull().sum().sort_values(ascending=False).head(10))

print("\nüî¢ Unique Labels:")
print(train_df["label"].value_counts())

print("\n‚úÖ Numeric Columns Count:", len(train_df.select_dtypes(include=[np.number]).columns))
print("‚úÖ Non-numeric Columns Count:", len(train_df.select_dtypes(exclude=[np.number]).columns))

# ==========================================
# 4Ô∏è‚É£ Target (Label) Distribution
# ==========================================
import matplotlib.pyplot as plt
import seaborn as sns


print("\nLabel distribution:")
print(train_df['label'].value_counts())


# Get top 15 labels
label_counts = train_df['label'].value_counts().reset_index().head(15)
label_counts.columns = ['Attack Type', 'Count']  # rename for clarity

plt.figure(figsize=(12,6))
sns.barplot(data=label_counts, x='Attack Type', y='Count', palette='viridis')
plt.xticks(rotation=75)
plt.title("Top 15 Most Frequent Labels in CICIoMT2023")
plt.xlabel("Attack Type")
plt.ylabel("Number of Samples")
plt.tight_layout()
plt.show()

# ==========================================
# 5Ô∏è‚É£ Protocol Type and Traffic Insights
# ==========================================

if "Protocol Type" in train_df.columns:
    # Clean up protocol values ‚Äî round to nearest integer
    train_df["Protocol Type"] = train_df["Protocol Type"].round().astype(int)

    # Map known protocol numbers to names (IANA standard)
    protocol_map = {
        1: "ICMP",
        6: "TCP",
        17: "UDP",
        2: "IGMP",
        47: "GRE",
        50: "ESP",
        51: "AH",
        58: "ICMPv6",
        89: "OSPF"
    }

    train_df["Protocol Name"] = train_df["Protocol Type"].map(protocol_map).fillna("Other")

    plt.figure(figsize=(8,4))
    sns.countplot(
        x="Protocol Name",
        data=train_df,
        order=train_df["Protocol Name"].value_counts().index,
        palette="pastel"
    )
    plt.title("Protocol Distribution in IoMT Traffic")
    plt.xlabel("Protocol")
    plt.ylabel("Count")
    plt.tight_layout()
    plt.show()

    # Average statistics by protocol
    proto_summary = train_df.groupby("Protocol Name").agg({
        "flow_duration": "mean",
        "Rate": "mean",
        "Tot sum": "mean"
    }).reset_index()

    print("üìä Average flow stats by protocol:")
    display(proto_summary.head())

else:
    print("‚ö†Ô∏è 'Protocol Type' column not found.")

# ==========================================
# 6Ô∏è‚É£ Numeric Feature Distributions
# ==========================================
numeric_cols = train_df.select_dtypes(include=[np.number]).columns

# Plot distribution of selected features
sample_features = numeric_cols[:6]  # first 6 for readability
train_df[sample_features].hist(figsize=(12,8), bins=30)
plt.suptitle("Distribution of Selected Numeric Features", fontsize=16)
plt.show()

# ==========================================
# 7Ô∏è‚É£ Correlation Analysis
# ==========================================
corr_matrix = train_df.select_dtypes(include=[np.number]).corr()

plt.figure(figsize=(14,10))
sns.heatmap(corr_matrix, cmap="coolwarm", center=0, linewidths=0.3)
plt.title("Correlation Heatmap of Numeric Features", fontsize=14)
plt.show()

# Top correlated features with Rate
if "Rate" in corr_matrix.columns:
    print("üîó Top correlated features with 'Rate':")
    print(corr_matrix["Rate"].sort_values(ascending=False).head(10))

# ==========================================
# 8Ô∏è‚É£ Benign vs Attack Comparison
# ==========================================
train_df["is_attack"] = (train_df["label"] != "BenignTraffic").astype(int)

feature_compare = ["flow_duration", "Tot sum", "Rate", "Min", "Max"]
for feat in feature_compare:
    if feat in train_df.columns:
        plt.figure(figsize=(6,4))
        sns.boxplot(x="is_attack", y=feat, data=train_df, palette="Set2")
        plt.title(f"Feature Comparison by Traffic Type ‚Äî {feat}")
        plt.xlabel("0 = Benign | 1 = Attack")
        plt.tight_layout()
        plt.show()

# ==========================================
# 9Ô∏è‚É£ Feature Importance (Random Forest Baseline)
# ==========================================
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

df = train_df.copy()
df = df.select_dtypes(include=[np.number]).fillna(0)

# Prepare binary target
df["is_attack"] = (train_df["label"] != "BenignTraffic").astype(int)

X = df.drop(columns=["is_attack"])
y = df["is_attack"]

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

rf = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)
rf.fit(X_train, y_train)

importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)[:15]
plt.figure(figsize=(10,6))
sns.barplot(x=importances, y=importances.index, palette="viridis")
plt.title("Top 15 Most Important Features (Random Forest Baseline)")
plt.xlabel("Importance Score")
plt.show()